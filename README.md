# sarcasm_detector_lstm
Developed an LSTM-based sarcasm detection model that leverages deep learning and NLP techniques to classify news headlines, highlighting AIâ€™s ability to interpret linguistic nuances.  Achieved a 87.84% Validation Accuracy, 0.3389 Validation Loss, and 95.55% accuracy when tested on entire dataset. 

# ğŸ§  Sarcasm Detection Using LSTM

## ğŸš€ Motivation & Project Overview  
AI, specifically text generator AIs, can summarize and reword news articles, but how well can AI **understand nuanced sentiment**?  

Sarcasm is unique because it often **contradicts the literal meaning** of the words used. Unlike traditional sentiment analysis models, which classify emotions as **positive, negative, or neutral**, sarcasm detection requires **contextual awareness** and a deeper understanding of language to recognize irony.  

This project focuses on developing an **NLP sarcasm detection model** using the **"News Headlines Dataset For Sarcasm Detection"** from Kaggle, created by **Rishabh Misra**, containing **26,000+ labeled news headlines**.  

The dataset is sourced from:  
- ğŸ“° **The Onion** (*satirical news, sarcastic headlines*)  
- ğŸ“° **HuffPost** (*non-satirical, factual headlines*)  

For this project, I implemented a **Long Short-Term Memory (LSTM) network**, a specialized type of **Recurrent Neural Network (RNN)** designed to process sequential text data. Unlike traditional neural networks, LSTMs **retain memory** from previous inputs, making them effective for understanding **sentence structure and context**â€”both crucial for sarcasm detection.

## ğŸ“š Dataset Source  

This project utilizes the **"News Headlines Dataset For Sarcasm Detection"**, originally published by **Rishabh Misra**.  

### ğŸ”— **Citations:**  
- Misra, Rishabh, and Prahal Arora. **"Sarcasm Detection using News Headlines Dataset."** *AI Open* (2023).  
- Misra, Rishabh, and Jigyasa Grover. **"Sculpting Data for ML: The First Act of Machine Learning."** ISBN 9798585463570 (2021).  

---

## ğŸ“Œ Project Workflow  

### ğŸ” **Data Analysis & Preprocessing**  
âœ”ï¸ Loaded and analyzed the dataset, examining the **distribution of sarcastic vs. non-sarcastic headlines**.  
âœ”ï¸ Extracted the **most frequently used words** in each category to identify patterns.  
âœ”ï¸ Created a **word cloud visualization** to highlight the most common words in sarcastic vs. non-sarcastic headlines.  

---

### ğŸ— **Building the LSTM Model**  
âœ”ï¸ **LSTM Layers** to retain sequential context and capture sentence structure.  
âœ”ï¸ **Dropout** to prevent overfitting by randomly deactivating neurons during training.  
âœ”ï¸ **Dense Layers** to refine extracted features for classification.  
âœ”ï¸ **ReLU Activation** in dense layers for efficient learning.  
âœ”ï¸ **Sigmoid Activation** in the output layer to produce a **probability score** for sarcasm detection.  

---

### âš™ **Hyperparameter Tuning**  
This project wasnâ€™t just about optimizing accuracy, but also about understanding **how different hyperparameters impact** the LSTM model by testing:  

âœ”ï¸ **Train/Test Split Ratios** â†’ Finding the best balance of training vs. validation data.  
âœ”ï¸ **Dropout Rates** â†’ Preventing overfitting while maintaining model performance.  
âœ”ï¸ **L1 & L2 Regularization** â†’ Controlling complexity and reducing reliance on specific features.  
âœ”ï¸ **Number of LSTM Layers** â†’ Testing if increasing depth improves performance.  
âœ”ï¸ **Dense Layers & Neurons** â†’ Exploring the trade-off between model complexity and efficiency.  

After tuning, I combined my findings to construct an **optimized model**.  

---

## ğŸ† Best Model Overview  
The **best-performing LSTM sarcasm detection model** achieved an accuracy of **87.84%** on the test set. This configuration optimized key hyperparameters to enhance generalization and performance.  

### **ğŸ“Œ Model Configuration:**  
- **Dropout:** 0.6  
- **L1 Regularization:** 0.01  
- **Train/Test Split:** 5/95  
- **Architecture:** Maintained the original LSTM and Dense layers  
- **Saved Model:** `best_sarcasm_LSTM_model3.keras`  

### **ğŸ“Š Training & Validation Metrics:**  
| Metric            | Value   |
|------------------|--------|
| **Training Accuracy** | 92.46% |
| **Training Loss** | 0.2845 |
| **Validation Accuracy** | 87.84% |
| **Validation Loss** | 0.3389 |

When tested on the **entire dataset**, the model achieved an accuracy of **95.55%**, which was expected since it was trained on this data.

---

## ğŸ”¬ Real-World Headline Evaluation  
To further validate the model, I tested it on **previously unseen headlines** to evaluate real-world performance. These headlines include both **sarcastic** and **non-sarcastic** examples from current events and manually written statements.

### **ğŸ“° Sample Headlines & Model Predictions:**  
âœ… *"A new hurricane is approaching East Atlantic."* â†’ **Non-Sarcastic (Correct)**  
âœ… *"Breaking: Local Man Shocked to Discover Monday Comes Every Week."* â†’ **Sarcastic (Correct)**  
âœ… *"Experts Warn That Doing Nothing Will Definitely Fix the Economy."* â†’ **Sarcastic (Correct)**  
âœ… *"Donald Trump executes tariffs for the U.S."* â†’ **Non-Sarcastic (Correct)**  
âœ… *"Study Finds 100% of People Eventually Die."* â†’ **Sarcastic (Correct)**  
âœ… *"Brilliant Political Plan Solves Everything, Announces Nobody."* â†’ **Sarcastic (Correct)**  
âŒ *"New York Times columnist admits scientists â€˜badly misledâ€™ public on COVID-19: â€˜Five years too lateâ€™."* â†’ **Misclassified (Should be Non-Sarcastic)**  
âœ… *"Greenpeace must pay over \$660M in case over Dakota Access protest activities, jury finds."* â†’ **Non-Sarcastic (Correct)**  
âœ… *"Trump administration says it's cutting \$175 million in funding to the University of Pennsylvania."* â†’ **Non-Sarcastic (Correct)**  
âœ… *"Forgetful Man Playing Fast And Loose With Free Trials."* â†’ **Sarcastic (Correct)**  

### **ğŸ¤” Observations:**  
The model **correctly classified 9 out of 10 headlines**. The only misclassification occurred with:  
- **Misclassified Headline:** *"New York Times columnist admits scientists â€˜badly misledâ€™ public on COVID-19: â€˜Five years too lateâ€™."*  
- This misclassification is interesting because **while the statement is intended as straightforward news, it has a tone that could be interpreted as sarcastic**, possibly explaining the model's error.

---

## ğŸ›  Skills Applied  
âœ”ï¸ **Deep Learning & Neural Networks**: Gained expertise in **LSTMs** for sarcasm detection, including **sequential data processing** and **hyperparameter tuning**.  
âœ”ï¸ **Natural Language Processing (NLP)**: Applied **text tokenization, stopword analysis, and word embeddings** to process textual data.  
âœ”ï¸ **Model Architecture Design**: Implemented **stacked LSTM layers, Dense layers, and Dropout** for sarcasm detection.  
âœ”ï¸ **Overfitting Prevention & Regularization**: Experimented with **Dropout rates, L1 & L2 regularization, learning rates, and train/test split sizes** to improve generalization.  

---

## ğŸ Final Thoughts  
This project **showcases the intersection of AI and linguistics**, demonstrating how **LSTM-based machine learning models can classify sarcasm** and enhance sentiment analysis in real-world text processing.  

---

## ğŸ“‚ Repository Contents  
- ğŸ“œ **`sarcasm_detection_lstm.ipynb`** â†’ Jupyter Notebook with model training, evaluation, and visualizations.  
- ğŸ“Š **`word_clouds_including_stop_words.png`** â†’ Word cloud visualizations of sarcastic vs. non-sarcastic words (including stop words).
- ğŸ“Š **`word_clouds_excluding_stop_words.png`** â†’ Word cloud visualizations of sarcastic vs. non-sarcastic words (excluding stop words).  
- ğŸ“„ **`best_sarcasm_LSTM_model3.keras`** â†’ Saved model file for reuse.  
---

## ğŸ“¢ Contact  
For questions or improvements, feel free to open an issue or contribute!  
ğŸ“š Personal Website: www.manreetsohi.com  

